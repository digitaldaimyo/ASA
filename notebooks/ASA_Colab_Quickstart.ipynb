{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASA Colab Quickstart \u2014 Functional Validation\n",
    "\n",
    "This notebook runs a fast, CPU-only validation pass for the ASA variants.\n",
    "It checks shapes, gradients, determinism, masking, routing overrides, and intervention toggles.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Status Dashboard\n",
    "results = []\n",
    "\n",
    "def record(name, ok, details=\"\"):\n",
    "    results.append({\"name\": name, \"ok\": bool(ok), \"details\": details})\n",
    "\n",
    "def finalize():\n",
    "    print(\"\\n=== STATUS DASHBOARD ===\")\n",
    "    for item in results:\n",
    "        status = \"PASS\" if item[\"ok\"] else \"FAIL\"\n",
    "        details = f\" - {item['details']}\" if item['details'] else \"\"\n",
    "        print(f\"{status:>4} | {item['name']}{details}\")\n",
    "    overall = all(item[\"ok\"] for item in results) if results else True\n",
    "    print(f\"OVERALL: {'PASS' if overall else 'FAIL'}\")\n",
    "    if not overall:\n",
    "        raise AssertionError(\"One or more checks failed.\")\n",
    "\n",
    "def print_section(title):\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "\n",
    "def assert_finite(tensor, name):\n",
    "    if not tensor.isfinite().all():\n",
    "        raise AssertionError(f\"Non-finite values in {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Section 0 \u2014 Environment & Setup\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "import random\n",
    "\n",
    "print_section('Environment & Setup')\n",
    "repo_dir = 'ASA'\n",
    "if not os.path.isdir(repo_dir):\n",
    "    print('Cloning repo...')\n",
    "    result = subprocess.run(['git', 'clone', 'https://github.com/digitaldaimyo/ASA.git'])\n",
    "    if result.returncode != 0:\n",
    "        print('Failed to clone. Next steps:')\n",
    "        print(' - Ensure Colab has write permissions to /content')\n",
    "        print(' - Restart the runtime and try again')\n",
    "        raise RuntimeError('git clone failed')\n",
    "if os.path.isdir(repo_dir):\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "print('Installing package (editable)...')\n",
    "result = subprocess.run([sys.executable, '-m', 'pip', 'install', '-e', '.'])\n",
    "if result.returncode != 0:\n",
    "    raise RuntimeError('pip install failed')\n",
    "\n",
    "import torch\n",
    "print(f'Python: {platform.python_version()}')\n",
    "print(f'Torch: {torch.__version__}')\n",
    "print('Device: cpu')\n",
    "\n",
    "seed = 1337\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "try:\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    print('Deterministic algorithms enabled.')\n",
    "except Exception as exc:\n",
    "    print(f'Warning: deterministic algorithms not fully enforced ({exc}).')\n",
    "record('setup', True, 'environment ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Section 1 \u2014 Import & API Surface Validation\n",
    "print_section('Import & API Surface Validation')\n",
    "import inspect\n",
    "from asa import AddressedStateAttention, AddressedStateAttentionOnline, AddressedStateAttentionIntervene\n",
    "\n",
    "variants = [\n",
    "    (AddressedStateAttention, 'baseline'),\n",
    "    (AddressedStateAttentionOnline, 'online'),\n",
    "    (AddressedStateAttentionIntervene, 'intervene'),\n",
    "]\n",
    "\n",
    "try:\n",
    "    for cls, label in variants:\n",
    "        sig = inspect.signature(cls)\n",
    "        for arg in ('embed_dim', 'num_heads', 'num_slots'):\n",
    "            if arg not in sig.parameters:\n",
    "                raise AssertionError(f'{label} missing arg: {arg}')\n",
    "        model = cls(embed_dim=32, num_heads=4, num_slots=8)\n",
    "        x = torch.randn(2, 5, 32)\n",
    "        out, info = model(x)\n",
    "        assert isinstance(out, torch.Tensor)\n",
    "        assert out.shape == x.shape\n",
    "        assert info is None or isinstance(info, dict)\n",
    "    record('api surface', True, 'imports/shape ok')\n",
    "except Exception as exc:\n",
    "    record('api surface', False, str(exc))\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Section 2 \u2014 Gradients & Parameter Update Sanity\n",
    "print_section('Gradients & Parameter Update Sanity')\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "\n",
    "def grad_and_update(cls, label):\n",
    "    model = cls(embed_dim=32, num_heads=4, num_slots=8)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    x = torch.randn(2, 8, 32)\n",
    "    vec_before = parameters_to_vector([p.detach().clone() for p in model.parameters()])\n",
    "    nonzero_grads = 0\n",
    "    for _ in range(3):\n",
    "        out, _ = model(x)\n",
    "        loss = out.pow(2).mean() + 0.01 * out.mean()\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None and p.grad.detach().abs().sum() > 0:\n",
    "                nonzero_grads += 1\n",
    "        optim.step()\n",
    "    vec_after = parameters_to_vector([p.detach() for p in model.parameters()])\n",
    "    changed = (vec_after - vec_before).abs().sum().item()\n",
    "    return nonzero_grads, changed\n",
    "\n",
    "try:\n",
    "    for cls, label in variants:\n",
    "        grads, delta = grad_and_update(cls, label)\n",
    "        assert grads > 0, f'{label}: no nonzero grads'\n",
    "        assert delta > 0, f'{label}: params did not change'\n",
    "    record('gradients/update', True, 'nonzero grads + params updated')\n",
    "except Exception as exc:\n",
    "    record('gradients/update', False, str(exc))\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Section 3 \u2014 Seeded Determinism (CPU)\n",
    "print_section('Seeded Determinism (CPU)')\n",
    "def deterministic_check(cls, label):\n",
    "    torch.manual_seed(123)\n",
    "    model1 = cls(embed_dim=32, num_heads=4, num_slots=8).eval()\n",
    "    x = torch.randn(2, 6, 32)\n",
    "    out1, _ = model1(x)\n",
    "    torch.manual_seed(123)\n",
    "    model2 = cls(embed_dim=32, num_heads=4, num_slots=8).eval()\n",
    "    out2, _ = model2(x)\n",
    "    assert torch.allclose(out1, out2, atol=1e-6), f'{label}: deterministic mismatch'\n",
    "    torch.manual_seed(124)\n",
    "    model3 = cls(embed_dim=32, num_heads=4, num_slots=8).eval()\n",
    "    out3, _ = model3(x)\n",
    "    assert not torch.allclose(out1, out3, atol=1e-6), f'{label}: seed did not change output'\n",
    "\n",
    "try:\n",
    "    for cls, label in variants:\n",
    "        deterministic_check(cls, label)\n",
    "    record('determinism', True, 'seeded outputs stable')\n",
    "except Exception as exc:\n",
    "    record('determinism', False, str(exc))\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Section 4 \u2014 Slot Count / Head Count Invariants\n",
    "print_section('Slot/Head Count Invariants')\n",
    "table = []\n",
    "try:\n",
    "    for heads in (1, 2, 4):\n",
    "        for slots in (4, 8, 16):\n",
    "            model = AddressedStateAttention(embed_dim=32, num_heads=heads, num_slots=slots)\n",
    "            x = torch.randn(2, 4, 32)\n",
    "            out, _ = model(x)\n",
    "            assert out.shape == x.shape\n",
    "            table.append((heads, slots, 'ok'))\n",
    "    print('heads | slots | status')\n",
    "    for h, s, st in table:\n",
    "        print(f'{h:>5} | {s:>5} | {st}')\n",
    "    record('slot/head sweep', True, 'all configs ok')\n",
    "except Exception as exc:\n",
    "    record('slot/head sweep', False, str(exc))\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Section 5 \u2014 Masking / Control Surface Tests\n",
    "print_section('Masking Controls')\n",
    "try:\n",
    "    model = AddressedStateAttention(embed_dim=32, num_heads=4, num_slots=8)\n",
    "    if 'slot_mask' in inspect.signature(model.forward).parameters:\n",
    "        x = torch.randn(2, 6, 32)\n",
    "        out_base, _ = model(x)\n",
    "        mask_half = torch.tensor([1, 1, 1, 1, 0, 0, 0, 0], dtype=torch.bool)\n",
    "        out_mask, _ = model(x, slot_mask=mask_half)\n",
    "        diff = (out_base - out_mask).abs().mean().item()\n",
    "        assert diff > 1e-6, 'mask did not change output'\n",
    "        mask_zero = torch.zeros(8, dtype=torch.bool)\n",
    "        out_zero, _ = model(x, slot_mask=mask_zero)\n",
    "        assert_finite(out_zero, 'masked output')\n",
    "        max_abs = out_zero.abs().max().item()\n",
    "        assert max_abs < 1e-5, f'zero-mask output too large: {max_abs}'\n",
    "        record('masking', True, 'mask affects output + zero-mask safe')\n",
    "    else:\n",
    "        record('masking', True, 'masking controls not exposed')\n",
    "except Exception as exc:\n",
    "    record('masking', False, str(exc))\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Section 6 \u2014 Routing Override Hook Test\n",
    "print_section('Routing Override Hook')\n",
    "try:\n",
    "    model = AddressedStateAttentionIntervene(embed_dim=32, num_heads=4, num_slots=8)\n",
    "    if hasattr(model, 'routing_override'):\n",
    "        x = torch.randn(2, 6, 32)\n",
    "        out_base, _ = model(x)\n",
    "        def override_fn(t0, t1, read_logits, read_logits_key, read_logits_content, ctx):\n",
    "            k = ctx['K']\n",
    "            return torch.full_like(read_logits, 1.0 / k)\n",
    "        model.routing_override = override_fn\n",
    "        out_override, _ = model(x)\n",
    "        diff = (out_base - out_override).abs().mean().item()\n",
    "        assert diff > 1e-6, 'override did not change output'\n",
    "        model.routing_override = None\n",
    "        record('routing override', True, 'override changes output')\n",
    "    else:\n",
    "        record('routing override', True, 'hook not available')\n",
    "except Exception as exc:\n",
    "    record('routing override', False, str(exc))\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Section 7 \u2014 Online Variant Specific Check\n",
    "print_section('Online Variant Check')\n",
    "try:\n",
    "    model = AddressedStateAttentionOnline(embed_dim=32, num_heads=4, num_slots=8)\n",
    "    x = torch.randn(2, 6, 32)\n",
    "    out, info = model(x, return_info=True)\n",
    "    assert out.shape == x.shape\n",
    "    assert info is None or isinstance(info, dict)\n",
    "    record('online info', True, 'returned output + info')\n",
    "except Exception as exc:\n",
    "    record('online info', False, str(exc))\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Section 8 \u2014 Intervention Variant Toggle Behavior\n",
    "print_section('Intervention Toggle')\n",
    "try:\n",
    "    model = AddressedStateAttentionIntervene(embed_dim=32, num_heads=4, num_slots=8)\n",
    "    x = torch.randn(2, 6, 32)\n",
    "    out_base, _ = model(x)\n",
    "    if hasattr(model, '_intv_mode'):\n",
    "        model._intv_mode = 'orth_gate'\n",
    "        out_intv, _ = model(x)\n",
    "        diff = (out_base - out_intv).abs().mean().item()\n",
    "        assert diff > 1e-6, 'intervention did not change output'\n",
    "        assert_finite(out_intv, 'intervention output')\n",
    "        model._intv_mode = 'off'\n",
    "        record('intervention toggle', True, 'output changes + finite')\n",
    "    else:\n",
    "        record('intervention toggle', True, 'controls not exposed')\n",
    "except Exception as exc:\n",
    "    record('intervention toggle', False, str(exc))\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Section 9 \u2014 Final Summary\n",
    "finalize()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ASA Colab Quickstart",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}